#!/usr/bin/env python
"""
generate_brief.py
Generates an executive intelligence brief using Claude AI
"""

import os
import pandas as pd
from datetime import datetime, timezone
from anthropic import Anthropic
from dotenv import load_dotenv
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

def send_email_brief(brief_text):
    """Send intelligence brief via email"""
    sender = os.getenv("EMAIL_ADDRESS")
    recipient = os.getenv("EMAIL_RECIPIENT")
    password = os.getenv("EMAIL_PASSWORD")
    
    if not all([sender, recipient, password]):
        print("Email credentials not configured. Skipping email.")
        return False
    
    msg = MIMEMultipart('alternative')
    msg['Subject'] = f'Intelligence Brief - {datetime.now(timezone.utc).strftime("%B %d, %Y")}'
    msg['From'] = sender
    msg['To'] = recipient
    
    # Create HTML version for better formatting
    html = f"""
    <html>
      <body style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;">
        <h2 style="color: #1f77b4;">Daily Intelligence Brief</h2>
        <pre style="white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px;">
{brief_text}
        </pre>
        <hr>
        <p style="color: #666; font-size: 12px;">
          Generated by Moodlight Intelligence Platform<br>
          {datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")}
        </p>
      </body>
    </html>
    """
    
    msg.attach(MIMEText(html, 'html'))
    
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender, password)
            server.send_message(msg)
        print(f"✅ Email sent to {recipient}")
        return True
    except Exception as e:
        print(f"❌ Email failed: {e}")
        return False

load_dotenv()

client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

def load_recent_data():
    """Load last 24 hours of intelligence data"""
    # Try PostgreSQL first
    db_url = os.getenv("DATABASE_URL", "")
    if db_url:
        try:
            from sqlalchemy import create_engine
            db_url = db_url.replace("postgres://", "postgresql://", 1)
            engine = create_engine(db_url)
            df = pd.read_sql("SELECT * FROM news_scored", engine)
            if not df.empty:
                print(f"✅ Loaded {len(df)} rows from PostgreSQL")
                df['created_at'] = pd.to_datetime(df['created_at'], utc=True, errors='coerce')
                cutoff = datetime.now(timezone.utc) - pd.Timedelta(days=7)
                return df[df['created_at'] >= cutoff]
        except Exception as e:
            print(f"DB error: {e}")
    # Fallback to CSV
    df = pd.read_csv("news_scored.csv")
    df['created_at'] = pd.to_datetime(df['created_at'], utc=True, errors='coerce')

    # Last 7 days
    cutoff = datetime.now(timezone.utc) - pd.Timedelta(days=7)
    recent = df[df['created_at'] >= cutoff]

    return recent


def load_social_data():
    """Load social media data for sentiment analysis"""
    # Try social_scored.csv, fallback to backup
    for csv_path in ["social_scored.csv", "social_scored_backup.csv"]:
        if os.path.exists(csv_path):
            try:
                df = pd.read_csv(csv_path)
                df['created_at'] = pd.to_datetime(df['created_at'], utc=True, errors='coerce')
                cutoff = datetime.now(timezone.utc) - pd.Timedelta(days=7)
                recent = df[df['created_at'] >= cutoff]
                if not recent.empty:
                    print(f"✅ Loaded {len(recent)} social posts from {csv_path}")
                    return recent
            except Exception as e:
                print(f"Social data error ({csv_path}): {e}")
    print("⚠️ No social data available")
    return pd.DataFrame()

def prepare_intelligence_context(news_df, social_df=None):
    """Prepare context for AI briefing"""

    # Top topics by volume
    topic_counts = news_df['topic'].value_counts().head(5)

    # High intensity articles (4-5 severity)
    critical = news_df[news_df['intensity'] >= 4]

    # Geographic distribution
    country_counts = news_df['country'].value_counts().head(5)

    # Average intensity by topic
    topic_intensity = news_df.groupby('topic')['intensity'].mean().sort_values(ascending=False).head(5)

    context = f"""
INTELLIGENCE DATA SUMMARY (Last 7 Days)
==========================================

TOP TOPICS BY VOLUME:
{topic_counts.to_string()}

HIGHEST INTENSITY TOPICS:
{topic_intensity.round(2).to_string()}

CRITICAL SEVERITY ARTICLES ({len(critical)} total):
{critical[['text', 'country', 'intensity']].head(10).to_string()}

GEOGRAPHIC DISTRIBUTION:
{country_counts.to_string()}

Total Articles Analyzed: {len(news_df)}
"""

    # Add social data if available
    if social_df is not None and not social_df.empty:
        # Top social topics
        social_topics = social_df['topic'].value_counts().head(5)

        # Emotional sentiment distribution
        emotion_dist = social_df['emotion_top_1'].value_counts().head(5)

        # Empathy score distribution
        empathy_dist = social_df['empathy_label'].value_counts()

        # High engagement posts (top by engagement score)
        if 'engagement' in social_df.columns:
            top_engagement = social_df.nlargest(5, 'engagement')[['text', 'engagement', 'emotion_top_1', 'source']]
        else:
            top_engagement = social_df.head(5)[['text', 'emotion_top_1', 'source']]

        # Average empathy by topic (cultural temperature)
        topic_empathy = social_df.groupby('topic')['empathy_score'].mean().sort_values(ascending=False).head(5)

        context += f"""

SOCIAL PULSE & CULTURAL MOMENTUM
==========================================

TRENDING SOCIAL TOPICS:
{social_topics.to_string()}

DOMINANT EMOTIONS:
{emotion_dist.to_string()}

EMPATHY TEMPERATURE:
{empathy_dist.to_string()}

CULTURAL HEAT BY TOPIC (Empathy Score):
{topic_empathy.round(2).to_string()}

HIGH-ENGAGEMENT CONTENT:
{top_engagement.to_string()}

Total Social Posts Analyzed: {len(social_df)}
"""

    return context

def generate_brief(context):
    """Generate executive brief using Claude AI"""

    prompt = f"""You are an intelligence analyst preparing a daily intelligence brief.

Based on the following intelligence data, create a concise executive summary.

Format as:
DAILY INTELLIGENCE BRIEF - {datetime.now(timezone.utc).strftime("%B %d, %Y")}

KEY THREATS:
[Top 3-5 high-intensity items requiring attention]

EMERGING PATTERNS:
[Notable trends, shifts, or developments across topics and regions]

RECOMMENDED ACTIONS:
[Prioritized actionable items based on the intelligence]

Keep it under 400 words. Use clear, direct language.

DATA:
{context}
"""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=500,
        system="You are a senior intelligence analyst providing daily situational awareness briefings.",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.content[0].text

def main():
    print("=" * 60)
    print("GENERATING EXECUTIVE INTELLIGENCE BRIEF")
    print("=" * 60)
    print()

    news_df = load_recent_data()
    social_df = load_social_data()

    if len(news_df) == 0 and len(social_df) == 0:
        print("No recent data available for briefing.")
        return

    print(f"Analyzing {len(news_df)} news articles + {len(social_df)} social posts...")
    print()

    context = prepare_intelligence_context(news_df, social_df)
    brief = generate_brief(context)
    
    print(brief)
    print()
    print("=" * 60)
    
    # Save to file
    timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    filename = f"intel_brief_{timestamp}.txt"
    
    with open(filename, 'w') as f:
        f.write(brief)
    
    print(f"Brief saved to: {filename}")

    # Send email
    send_email_brief(brief)

if __name__ == "__main__":
    main()
